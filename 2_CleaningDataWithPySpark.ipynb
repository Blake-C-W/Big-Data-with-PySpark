{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!wget -O AA_DFW_2014.csv.gz https://assets.datacamp.com/production/repositories/4336/datasets/f412f5acbef38630147c2956d8703bafbcd0f74c/AA_DFW_2014_Departures_Short.csv.gz\n",
        "!wget -O AA_DFW_2015.csv.gz https://assets.datacamp.com/production/repositories/4336/datasets/475d2803541ba8facb2c39024dd0d9497859dc6c/AA_DFW_2015_Departures_Short.csv.gz\n",
        "!wget -O AA_DFW_2016.csv.gz https://assets.datacamp.com/production/repositories/4336/datasets/c1abacafea802998597d6c68b27c7b8650a18ab8/AA_DFW_2016_Departures_Short.csv.gz\n",
        "!wget -O AA_DFW_2017.csv.gz https://assets.datacamp.com/production/repositories/4336/datasets/04db01ffbd39f7bf2f88ffd5b7924b2de0419168/AA_DFW_2017_Departures_Short.csv.gz\n",
        "!wget -O votes.csv.gz https://assets.datacamp.com/production/repositories/4336/datasets/ea700976560a6f1760782c6e7310a662120c63b5/DallasCouncilVotes.csv.gz\n",
        "!wget -O voters.csv.gz https://assets.datacamp.com/production/repositories/4336/datasets/c0aa672020bce21eef0d875a484a4fd44da042cf/DallasCouncilVoters.csv.gz"
      ],
      "metadata": {
        "id": "HYYl_j563oRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9HOyo2AmzqF"
      },
      "outputs": [],
      "source": [
        "%pip install pyspark[sql]\n",
        "%pip install pyspark[pandas_on_spark]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession, functions as F\n",
        "from pyspark.sql.types import *\n",
        "import time"
      ],
      "metadata": {
        "id": "buFV653FobLQ"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configure Spark Session"
      ],
      "metadata": {
        "id": "lBhe_FEronfT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder \\\n",
        "    .appName(\"DataCamp Locally\") \\\n",
        "    .master(\"local\") \\\n",
        "    .config(\"spark.driver.memory\", \"4g\") \\\n",
        "    .config(\"spark.executor.memory\", \"4g\") \\\n",
        "    .config(\"spark.ui.port\", \"4040\") \\\n",
        "    .config(\"spark.ui.bindAddress\", \"127.0.0.1\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "5Vy-9jLIoqGN"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Schema"
      ],
      "metadata": {
        "id": "1XiiLVTl24zo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a new schema using the StructType method\n",
        "people_schema = StructType([\n",
        "  # Define a StructField for each field\n",
        "  StructField('name', StringType(), False),\n",
        "  StructField('age', IntegerType(), False),\n",
        "  StructField('city', StringType(), False)\n",
        "])"
      ],
      "metadata": {
        "id": "fXTkK37ro6QW"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aa_dfw_df = spark.read.format('csv').options(Header=True).load('/content/AA_DFW_2017.csv.gz')\n",
        "aa_dfw_df = aa_dfw_df.withColumn('airport', F.lower(aa_dfw_df['Destination Airport']))\n",
        "aa_dfw_df = aa_dfw_df.drop(aa_dfw_df['Destination Airport'])\n",
        "aa_dfw_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9yMAMR54rWV",
        "outputId": "3547a1de-b1b4-4b1d-9ed7-1361edd7f1f2"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-------------+-----------------------------+-------+\n",
            "|Date (MM/DD/YYYY)|Flight Number|Actual elapsed time (Minutes)|airport|\n",
            "+-----------------+-------------+-----------------------------+-------+\n",
            "|       01/01/2017|         0005|                          537|    hnl|\n",
            "|       01/01/2017|         0007|                          498|    ogg|\n",
            "|       01/01/2017|         0037|                          241|    sfo|\n",
            "|       01/01/2017|         0043|                          134|    dtw|\n",
            "|       01/01/2017|         0051|                           88|    stl|\n",
            "|       01/01/2017|         0060|                          149|    mia|\n",
            "|       01/01/2017|         0071|                          203|    lax|\n",
            "|       01/01/2017|         0074|                           76|    mem|\n",
            "|       01/01/2017|         0081|                          123|    den|\n",
            "|       01/01/2017|         0089|                          161|    slc|\n",
            "|       01/01/2017|         0096|                           84|    stl|\n",
            "|       01/01/2017|         0103|                          216|    sjc|\n",
            "|       01/01/2017|         0119|                          514|    ogg|\n",
            "|       01/01/2017|         0123|                          529|    hnl|\n",
            "|       01/01/2017|         0126|                          171|    lga|\n",
            "|       01/01/2017|         0132|                          188|    ewr|\n",
            "|       01/01/2017|         0140|                          231|    sjc|\n",
            "|       01/01/2017|         0174|                          145|    rdu|\n",
            "|       01/01/2017|         0176|                          184|    bos|\n",
            "|       01/01/2017|         0190|                           76|    sat|\n",
            "+-----------------+-------------+-----------------------------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To Parquet / Read Parquet"
      ],
      "metadata": {
        "id": "cEEHAMiA7wWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_flights = spark.read.csv(\"/content/AA_DFW_*.csv.gz\", header=True, inferSchema=True)\n",
        "all_flights.write.parquet('/content/AA_DFW_ALL.parquet', mode='overwrite')\n",
        "all_flights.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFAOKAzi6nn0",
        "outputId": "908b0429-9c35-42b1-d27a-5a29c63dd2c4"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-------------+-------------------+-----------------------------+\n",
            "|Date (MM/DD/YYYY)|Flight Number|Destination Airport|Actual elapsed time (Minutes)|\n",
            "+-----------------+-------------+-------------------+-----------------------------+\n",
            "|       01/01/2014|            5|                HNL|                          519|\n",
            "|       01/01/2014|            7|                OGG|                          505|\n",
            "|       01/01/2014|           35|                SLC|                          174|\n",
            "|       01/01/2014|           43|                DTW|                          153|\n",
            "|       01/01/2014|           52|                PIT|                          137|\n",
            "|       01/01/2014|           58|                SAN|                          174|\n",
            "|       01/01/2014|           60|                MIA|                          155|\n",
            "|       01/01/2014|           64|                JFK|                          185|\n",
            "|       01/01/2014|           90|                ORD|                          126|\n",
            "|       01/01/2014|           96|                STL|                           91|\n",
            "|       01/01/2014|           99|                SNA|                          182|\n",
            "|       01/01/2014|          103|                ONT|                          181|\n",
            "|       01/01/2014|          109|                DEN|                          127|\n",
            "|       01/01/2014|          122|                SFO|                          222|\n",
            "|       01/01/2014|          123|                HNL|                          510|\n",
            "|       01/01/2014|          129|                COS|                          114|\n",
            "|       01/01/2014|          130|                DCA|                          141|\n",
            "|       01/01/2014|          131|                SLC|                          167|\n",
            "|       01/01/2014|          132|                STL|                           82|\n",
            "|       01/01/2014|          140|                BWI|                          146|\n",
            "+-----------------+-------------+-------------------+-----------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flights_df = spark.read.parquet('AA_DFW_ALL.parquet')\n",
        "flights_df = flights_df.withColumn('Actual elapsed time (Minutes)', flights_df['Actual elapsed time (Minutes)'].cast(\"integer\"))\n",
        "flights_df.createOrReplaceTempView('flights')\n",
        "\n",
        "avg_duration = spark.sql('SELECT avg(`Actual elapsed time (Minutes)`) as avg_duration from flights').collect()[0]\n",
        "print(f'The average flight time is: {avg_duration[\"avg_duration\"]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Q4G7eiX8B54",
        "outputId": "52b5e4b7-1dd9-435b-e170-b83a039f828c"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The average flight time is: 147.59399915712726\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the distinct VOTER_NAME entries\n",
        "voter_df = spark.read.csv(\"/content/voters.csv.gz\", header=True, inferSchema=True)\n",
        "voter_df.select(voter_df['VOTER_NAME']).distinct().show(40)\n",
        "voter_df = voter_df.filter('length(VOTER_NAME) > 0 and length(VOTER_NAME) < 20')\n",
        "voter_df = voter_df.filter(~ F.col('VOTER_NAME').contains('_'))\n",
        "voter_df.select('VOTER_NAME').distinct().show(40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSjVXtlxBpbu",
        "outputId": "661e95c2-d8f4-4a22-9d1b-5cabe207d4fb"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|          VOTER_NAME|\n",
            "+--------------------+\n",
            "|      Tennell Atkins|\n",
            "|  the  final   20...|\n",
            "|        Scott Griggs|\n",
            "|       Scott  Griggs|\n",
            "|       Sandy Greyson|\n",
            "| Michael S. Rawlings|\n",
            "| the final 2018 A...|\n",
            "|        Kevin Felder|\n",
            "|        Adam Medrano|\n",
            "|       Casey  Thomas|\n",
            "|   the   final  2...|\n",
            "|          011018__42|\n",
            "|       Mark  Clayton|\n",
            "|        Casey Thomas|\n",
            "|      Sandy  Greyson|\n",
            "|        Mark Clayton|\n",
            "|  Jennifer S.  Gates|\n",
            "|   Tiffinni A. Young|\n",
            "|  the  final  201...|\n",
            "|    B. Adam  McGough|\n",
            "|        Omar Narvaez|\n",
            "|  Philip T. Kingston|\n",
            "|  Rickey D. Callahan|\n",
            "|   Dwaine R. Caraway|\n",
            "| Philip T.  Kingston|\n",
            "|   Jennifer S. Gates|\n",
            "|     Lee M. Kleinman|\n",
            "|    Monica R. Alonzo|\n",
            "|   the   final  2...|\n",
            "| Rickey D.  Callahan|\n",
            "| Carolyn King Arnold|\n",
            "|  the  final   20...|\n",
            "|         Erik Wilson|\n",
            "|  the  final  201...|\n",
            "|        Lee Kleinman|\n",
            "|                NULL|\n",
            "+--------------------+\n",
            "\n",
            "+-------------------+\n",
            "|         VOTER_NAME|\n",
            "+-------------------+\n",
            "|     Tennell Atkins|\n",
            "|       Scott Griggs|\n",
            "|      Scott  Griggs|\n",
            "|      Sandy Greyson|\n",
            "|Michael S. Rawlings|\n",
            "|       Kevin Felder|\n",
            "|       Adam Medrano|\n",
            "|      Casey  Thomas|\n",
            "|      Mark  Clayton|\n",
            "|       Casey Thomas|\n",
            "|     Sandy  Greyson|\n",
            "|       Mark Clayton|\n",
            "| Jennifer S.  Gates|\n",
            "|  Tiffinni A. Young|\n",
            "|   B. Adam  McGough|\n",
            "|       Omar Narvaez|\n",
            "| Philip T. Kingston|\n",
            "| Rickey D. Callahan|\n",
            "|  Dwaine R. Caraway|\n",
            "|Philip T.  Kingston|\n",
            "|  Jennifer S. Gates|\n",
            "|    Lee M. Kleinman|\n",
            "|   Monica R. Alonzo|\n",
            "|Rickey D.  Callahan|\n",
            "|Carolyn King Arnold|\n",
            "|        Erik Wilson|\n",
            "|       Lee Kleinman|\n",
            "+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "voter_df = voter_df.withColumn('splits', F.split(voter_df.VOTER_NAME, '\\s+'))\n",
        "voter_df = voter_df.withColumn('first_name', voter_df.splits.getItem(0))\n",
        "voter_df = voter_df.withColumn('last_name', voter_df.splits.getItem(F.size('splits') - 1))\n",
        "voter_df = voter_df.drop('splits')\n",
        "voter_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7gGYCSfCYIW",
        "outputId": "cdd48ec9-2b5f-4d66-b702-9ccae01902ba"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pyspark/sql/column.py:460: FutureWarning: A column as 'key' in getItem is deprecated as of Spark 3.0, and will not be supported in the future release. Use `column[key]` or `column.key` syntax instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------------+-------------------+----------+---------+\n",
            "|      DATE|        TITLE|         VOTER_NAME|first_name|last_name|\n",
            "+----------+-------------+-------------------+----------+---------+\n",
            "|02/08/2017|Councilmember|  Jennifer S. Gates|  Jennifer|    Gates|\n",
            "|02/08/2017|Councilmember| Philip T. Kingston|    Philip| Kingston|\n",
            "|02/08/2017|        Mayor|Michael S. Rawlings|   Michael| Rawlings|\n",
            "|02/08/2017|Councilmember|       Adam Medrano|      Adam|  Medrano|\n",
            "|02/08/2017|Councilmember|       Casey Thomas|     Casey|   Thomas|\n",
            "|02/08/2017|Councilmember|Carolyn King Arnold|   Carolyn|   Arnold|\n",
            "|02/08/2017|Councilmember|       Scott Griggs|     Scott|   Griggs|\n",
            "|02/08/2017|Councilmember|   B. Adam  McGough|        B.|  McGough|\n",
            "|02/08/2017|Councilmember|       Lee Kleinman|       Lee| Kleinman|\n",
            "|02/08/2017|Councilmember|      Sandy Greyson|     Sandy|  Greyson|\n",
            "|02/08/2017|Councilmember|  Jennifer S. Gates|  Jennifer|    Gates|\n",
            "|02/08/2017|Councilmember| Philip T. Kingston|    Philip| Kingston|\n",
            "|02/08/2017|        Mayor|Michael S. Rawlings|   Michael| Rawlings|\n",
            "|02/08/2017|Councilmember|       Adam Medrano|      Adam|  Medrano|\n",
            "|02/08/2017|Councilmember|       Casey Thomas|     Casey|   Thomas|\n",
            "|02/08/2017|Councilmember|Carolyn King Arnold|   Carolyn|   Arnold|\n",
            "|02/08/2017|Councilmember| Rickey D. Callahan|    Rickey| Callahan|\n",
            "|01/11/2017|Councilmember|  Jennifer S. Gates|  Jennifer|    Gates|\n",
            "|04/25/2018|Councilmember|     Sandy  Greyson|     Sandy|  Greyson|\n",
            "|04/25/2018|Councilmember| Jennifer S.  Gates|  Jennifer|    Gates|\n",
            "+----------+-------------+-------------------+----------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# When / Otherwise"
      ],
      "metadata": {
        "id": "pVO6YuNLD0vq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "voter_df = voter_df.withColumn('random_val',\n",
        "                               F.when(voter_df.TITLE == 'Councilmember', F.rand()))"
      ],
      "metadata": {
        "id": "HNiUx_MrDWbv"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a column to voter_df for a voter based on their position\n",
        "voter_df = voter_df.withColumn('random_val',\n",
        "                               F.when(voter_df.TITLE == 'Councilmember', F.rand())\n",
        "                               .when(voter_df.TITLE == 'Mayor', 2)\n",
        "                               .otherwise(0))\n",
        "\n",
        "voter_df.filter(voter_df.random_val == 0).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Scrv8Fe4D3Hb",
        "outputId": "7f1561ca-cf3e-4f3f-e613-969a645ad0f3"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------------------+-----------------+----------+---------+----------+\n",
            "|      DATE|               TITLE|       VOTER_NAME|first_name|last_name|random_val|\n",
            "+----------+--------------------+-----------------+----------+---------+----------+\n",
            "|04/25/2018|Deputy Mayor Pro Tem|     Adam Medrano|      Adam|  Medrano|       0.0|\n",
            "|04/25/2018|       Mayor Pro Tem|Dwaine R. Caraway|    Dwaine|  Caraway|       0.0|\n",
            "|06/20/2018|Deputy Mayor Pro Tem|     Adam Medrano|      Adam|  Medrano|       0.0|\n",
            "|06/20/2018|       Mayor Pro Tem|Dwaine R. Caraway|    Dwaine|  Caraway|       0.0|\n",
            "|06/20/2018|Deputy Mayor Pro Tem|     Adam Medrano|      Adam|  Medrano|       0.0|\n",
            "|06/20/2018|       Mayor Pro Tem|Dwaine R. Caraway|    Dwaine|  Caraway|       0.0|\n",
            "|08/15/2018|Deputy Mayor Pro Tem|     Adam Medrano|      Adam|  Medrano|       0.0|\n",
            "|08/15/2018|Deputy Mayor Pro Tem|     Adam Medrano|      Adam|  Medrano|       0.0|\n",
            "|09/18/2018|Deputy Mayor Pro Tem|     Adam Medrano|      Adam|  Medrano|       0.0|\n",
            "|09/18/2018|       Mayor Pro Tem|    Casey  Thomas|     Casey|   Thomas|       0.0|\n",
            "|04/25/2018|Deputy Mayor Pro Tem|     Adam Medrano|      Adam|  Medrano|       0.0|\n",
            "|04/25/2018|       Mayor Pro Tem|Dwaine R. Caraway|    Dwaine|  Caraway|       0.0|\n",
            "|04/11/2018|       Mayor Pro Tem|Dwaine R. Caraway|    Dwaine|  Caraway|       0.0|\n",
            "|04/11/2018|Deputy Mayor Pro Tem|     Adam Medrano|      Adam|  Medrano|       0.0|\n",
            "|04/11/2018|       Mayor Pro Tem|Dwaine R. Caraway|    Dwaine|  Caraway|       0.0|\n",
            "|04/11/2018|Deputy Mayor Pro Tem|     Adam Medrano|      Adam|  Medrano|       0.0|\n",
            "|04/11/2018|       Mayor Pro Tem|Dwaine R. Caraway|    Dwaine|  Caraway|       0.0|\n",
            "|06/13/2018|Deputy Mayor Pro Tem|     Adam Medrano|      Adam|  Medrano|       0.0|\n",
            "|06/13/2018|       Mayor Pro Tem|Dwaine R. Caraway|    Dwaine|  Caraway|       0.0|\n",
            "|04/11/2018|Deputy Mayor Pro Tem|     Adam Medrano|      Adam|  Medrano|       0.0|\n",
            "+----------+--------------------+-----------------+----------+---------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defined Functions"
      ],
      "metadata": {
        "id": "fR0HyHBKEiKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "voter_df = voter_df.withColumn('splits', F.split(voter_df.VOTER_NAME, '\\s+'))\n",
        "\n",
        "def getFirstAndMiddle(names):\n",
        "  # Return a space separated string of names\n",
        "  return ' '.join(names[:-1])\n",
        "\n",
        "# Define the method as a UDF\n",
        "udfFirstAndMiddle = F.udf(getFirstAndMiddle, StringType())\n",
        "\n",
        "# Create a new column using your UDF\n",
        "voter_df = voter_df.withColumn('first_and_middle_name', udfFirstAndMiddle(voter_df.splits))\n",
        "\n",
        "# Show the DataFrame\n",
        "voter_df = voter_df.drop('splits')\n",
        "voter_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yMnq4c1Ejnk",
        "outputId": "dbe5b233-fe7b-4f8c-f8a5-c36283205046"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------------+-------------------+----------+---------+--------------------+---------------------+\n",
            "|      DATE|        TITLE|         VOTER_NAME|first_name|last_name|          random_val|first_and_middle_name|\n",
            "+----------+-------------+-------------------+----------+---------+--------------------+---------------------+\n",
            "|02/08/2017|Councilmember|  Jennifer S. Gates|  Jennifer|    Gates|  0.2987287340381092|          Jennifer S.|\n",
            "|02/08/2017|Councilmember| Philip T. Kingston|    Philip| Kingston| 0.39570315564845493|            Philip T.|\n",
            "|02/08/2017|        Mayor|Michael S. Rawlings|   Michael| Rawlings|                 2.0|           Michael S.|\n",
            "|02/08/2017|Councilmember|       Adam Medrano|      Adam|  Medrano|  0.5215374774190792|                 Adam|\n",
            "|02/08/2017|Councilmember|       Casey Thomas|     Casey|   Thomas|0.017804270476997397|                Casey|\n",
            "|02/08/2017|Councilmember|Carolyn King Arnold|   Carolyn|   Arnold|  0.8564584398287882|         Carolyn King|\n",
            "|02/08/2017|Councilmember|       Scott Griggs|     Scott|   Griggs|  0.2555185332430475|                Scott|\n",
            "|02/08/2017|Councilmember|   B. Adam  McGough|        B.|  McGough|  0.4765077861727821|              B. Adam|\n",
            "|02/08/2017|Councilmember|       Lee Kleinman|       Lee| Kleinman| 0.10491985150203531|                  Lee|\n",
            "|02/08/2017|Councilmember|      Sandy Greyson|     Sandy|  Greyson|  0.4349142328202781|                Sandy|\n",
            "|02/08/2017|Councilmember|  Jennifer S. Gates|  Jennifer|    Gates|  0.5730195775112529|          Jennifer S.|\n",
            "|02/08/2017|Councilmember| Philip T. Kingston|    Philip| Kingston| 0.16988656441433214|            Philip T.|\n",
            "|02/08/2017|        Mayor|Michael S. Rawlings|   Michael| Rawlings|                 2.0|           Michael S.|\n",
            "|02/08/2017|Councilmember|       Adam Medrano|      Adam|  Medrano|  0.3349105240572221|                 Adam|\n",
            "|02/08/2017|Councilmember|       Casey Thomas|     Casey|   Thomas|  0.6419533608547981|                Casey|\n",
            "|02/08/2017|Councilmember|Carolyn King Arnold|   Carolyn|   Arnold| 0.43243014148613235|         Carolyn King|\n",
            "|02/08/2017|Councilmember| Rickey D. Callahan|    Rickey| Callahan|  0.5747800118354358|            Rickey D.|\n",
            "|01/11/2017|Councilmember|  Jennifer S. Gates|  Jennifer|    Gates|  0.1218842545234754|          Jennifer S.|\n",
            "|04/25/2018|Councilmember|     Sandy  Greyson|     Sandy|  Greyson|  0.8168543224763556|                Sandy|\n",
            "|04/25/2018|Councilmember| Jennifer S.  Gates|  Jennifer|    Gates|  0.4227951294000314|          Jennifer S.|\n",
            "+----------+-------------+-------------------+----------+---------+--------------------+---------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adding an ID Field"
      ],
      "metadata": {
        "id": "sIHi1FMmGMMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select all the unique council voters\n",
        "voter_df = voter_df.select(voter_df[\"VOTER_NAME\"]).distinct()\n",
        "\n",
        "# Count the rows in voter_df\n",
        "print(\"\\nThere are %d rows in the voter_df DataFrame.\\n\" % voter_df.count())\n",
        "\n",
        "# Add a ROW_ID\n",
        "voter_df = voter_df.withColumn('ROW_ID', F.monotonically_increasing_id())\n",
        "\n",
        "# Show the rows with 10 highest IDs in the set\n",
        "voter_df.orderBy(voter_df.ROW_ID.desc()).show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwShDQY5GFDc",
        "outputId": "6afef008-8bf7-44cb-d90d-8b772642f9ad"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "There are 27 rows in the voter_df DataFrame.\n",
            "\n",
            "+-------------------+------+\n",
            "|         VOTER_NAME|ROW_ID|\n",
            "+-------------------+------+\n",
            "|       Lee Kleinman|    26|\n",
            "|        Erik Wilson|    25|\n",
            "|Carolyn King Arnold|    24|\n",
            "|Rickey D.  Callahan|    23|\n",
            "|   Monica R. Alonzo|    22|\n",
            "|    Lee M. Kleinman|    21|\n",
            "|  Jennifer S. Gates|    20|\n",
            "|Philip T.  Kingston|    19|\n",
            "|  Dwaine R. Caraway|    18|\n",
            "| Rickey D. Callahan|    17|\n",
            "+-------------------+------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ID with different Partitions"
      ],
      "metadata": {
        "id": "JKebSKuUHBUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the number of partitions in each DataFrame\n",
        "print(f\"\\nThere are {voter_df.rdd.getNumPartitions()} partitions in the voter_df DataFrame.\\n\")\n",
        "\n",
        "# Add a ROW_ID field to each DataFrame\n",
        "voter_df = voter_df.withColumn('ROW_ID', F.monotonically_increasing_id())\n",
        "\n",
        "# Show the top 10 IDs in each DataFrame\n",
        "voter_df.orderBy(voter_df.ROW_ID.desc()).show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rklWJCMFHD6A",
        "outputId": "5e65aacf-aa9d-48fd-edc1-1665a7f6fba6"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "There are 1 partitions in the voter_df DataFrame.\n",
            "\n",
            "+-------------------+------+\n",
            "|         VOTER_NAME|ROW_ID|\n",
            "+-------------------+------+\n",
            "|       Lee Kleinman|    26|\n",
            "|        Erik Wilson|    25|\n",
            "|Carolyn King Arnold|    24|\n",
            "|Rickey D.  Callahan|    23|\n",
            "|   Monica R. Alonzo|    22|\n",
            "|    Lee M. Kleinman|    21|\n",
            "|  Jennifer S. Gates|    20|\n",
            "|Philip T.  Kingston|    19|\n",
            "|  Dwaine R. Caraway|    18|\n",
            "| Rickey D. Callahan|    17|\n",
            "+-------------------+------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Improving Performance"
      ],
      "metadata": {
        "id": "lJX-N1SGH7BL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Caching"
      ],
      "metadata": {
        "id": "AcupVsrhH_Uk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "departures_df = spark.read.parquet('AA_DFW_ALL.parquet')\n",
        "\n",
        "# Add caching to the unique rows in departures_df\n",
        "departures_df = departures_df.distinct().cache()\n",
        "\n",
        "# Count the unique rows in departures_df, noting how long the operation takes\n",
        "print(f\"Counting {departures_df.count()} rows took {time.time() - start_time} seconds\")\n",
        "\n",
        "# Count the rows again, noting the variance in time of a cached DataFrame\n",
        "start_time = time.time()\n",
        "print(f\"Counting {departures_df.count()} rows took {time.time() - start_time} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuxPwDgkH919",
        "outputId": "985a1685-35f9-4a9e-8272-9d88c808f3ac"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counting 583718 rows took 18.604215383529663 seconds\n",
            "Counting 583718 rows took 4.329400539398193 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Removing a DataFrame from cache"
      ],
      "metadata": {
        "id": "YzOF0sO3J6VE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine if departures_df is in the cache\n",
        "print(f\"Is departures_df cached?: {departures_df.is_cached}\")\n",
        "print(f\"Removing departures_df from cache\")\n",
        "\n",
        "# Remove departures_df from the cache\n",
        "departures_df.unpersist()\n",
        "\n",
        "# Check the cache status again\n",
        "print(f\"Is departures_df cached?: {departures_df.is_cached}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZlTyJyGJ76k",
        "outputId": "275dcfbf-6db8-42ca-b1c3-c6d81c30652a"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is departures_df cached?: True\n",
            "Removing departures_df from cache\n",
            "Is departures_df cached?: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read Spark Configurations"
      ],
      "metadata": {
        "id": "00LhaXI3UzWk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Name of the Spark application instance\n",
        "app_name = spark.conf.get('spark.app.name')\n",
        "\n",
        "# Driver TCP port\n",
        "driver_tcp_port = spark.conf.get('spark.driver.port')\n",
        "\n",
        "# Number of join partitions\n",
        "num_partitions = spark.conf.get('spark.sql.shuffle.partitions')\n",
        "\n",
        "# Show the results\n",
        "print(f\"Name: {app_name}\")\n",
        "print(f\"Driver TCP port: {driver_tcp_port}\")\n",
        "print(f\"Number of partitions: {num_partitions}\")\n",
        "\n",
        "# Configure Spark to use 500 partitions\n",
        "spark.conf.set('spark.sql.shuffle.partitions', 500)\n",
        "print(f\"Number of partitions: {num_partitions}\")"
      ],
      "metadata": {
        "id": "L_0khQQAU2h6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Broadcasting"
      ],
      "metadata": {
        "id": "Ro3wnOEbWKCx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "voters = spark.read.csv(\"/content/voters.csv.gz\", header=True, inferSchema=True)\n",
        "votes = spark.read.csv(\"/content/votes.csv.gz\", header=True, inferSchema=True)\n",
        "\n",
        "# Join the flights_df and aiports_df DataFrames\n",
        "normal_df = voters.join(votes,\n",
        "  (voters[\"DATE\"] == votes[\"DATE\"]) &\n",
        "  (voters[\"VOTER_NAME\"] == votes[\"VOTER NAME\"]) &\n",
        "  (voters[\"TITLE\"] == votes[\"TITLE\"])\n",
        "  )\n",
        "\n",
        "# Show the query plan\n",
        "normal_df.explain()\n",
        "\n",
        "# Join the flights_df and airports_df DataFrames using broadcasting\n",
        "broadcast_df = F.broadcast(voters).join(votes,\n",
        "  (voters[\"DATE\"] == votes[\"DATE\"]) &\n",
        "  (voters[\"VOTER_NAME\"] == votes[\"VOTER NAME\"]) &\n",
        "  (voters[\"TITLE\"] == votes[\"TITLE\"])\n",
        "  )\n",
        "\n",
        "# broadcast_df = flights_df.join(F.broadcast(airports_df), \\\n",
        "#     flights_df[\"Destination Airport\"] == airports_df[\"IATA\"] )\n",
        "\n",
        "# Show the query plan and compare against the original\n",
        "broadcast_df.explain()"
      ],
      "metadata": {
        "id": "ND42bcXNWLPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparing Broadcast VS Normal"
      ],
      "metadata": {
        "id": "MBW9Us79YL6P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "# Count the number of rows in the normal DataFrame\n",
        "normal_count = normal_df.count()\n",
        "normal_duration = time.time() - start_time\n",
        "\n",
        "start_time = time.time()\n",
        "# Count the number of rows in the broadcast DataFrame\n",
        "broadcast_count = broadcast_df.count()\n",
        "broadcast_duration = time.time() - start_time\n",
        "\n",
        "# Print the counts and the duration of the tests\n",
        "print(f\"Normal count:\\t\\t{normal_count}\\tduration: {normal_duration}\")\n",
        "print(f\"Broadcast count:\\t{broadcast_count}\\tduration: {broadcast_duration}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Imq4sHLRYP6C",
        "outputId": "c7e40a6c-3576-4c1c-ff51-cb0c090245b8"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normal count:\t\t2960192\tduration: 3.3175344467163086\n",
            "Broadcast count:\t2960192\tduration: 2.2266414165496826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intro To Data Pipelines"
      ],
      "metadata": {
        "id": "gYYWNzICYuaU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quick Pipeline"
      ],
      "metadata": {
        "id": "Iz-qS2q4ZlK1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the data to a DataFrame\n",
        "departures_df = spark.read.csv('/content/AA_DFW_2015.csv.gz', header=True)\n",
        "\n",
        "# Remove any duration of 0\n",
        "departures_df = departures_df.filter(departures_df[3] > 0)\n",
        "\n",
        "# Add an ID column\n",
        "departures_df = departures_df.withColumn('id', F.monotonically_increasing_id())\n",
        "\n",
        "# Write the file out to JSON format\n",
        "departures_df.write.json('/content/output.json', mode='overwrite')"
      ],
      "metadata": {
        "id": "uFS8_pRLYype"
      },
      "execution_count": 76,
      "outputs": []
    }
  ]
}
